{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"168hmFOWa4SWoJeZNQ_EPls9rifx7b2wn","authorship_tag":"ABX9TyP5NzQ6RyEUXTmzUCJGZm+e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","import tensorflow as tf\n","from tensorflow import keras\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","\n","\n","# 数据准备\n","def load_images(df, path_prefix):\n","    image_list = []\n","    for idx, row in df.iterrows():\n","        img_path = os.path.join(path_prefix, row['filepaths'])\n","        img = Image.open(img_path).resize((224, 224))\n","        img_array = np.array(img) / 255.0\n","        image_list.append(img_array)\n","    return np.array(image_list)\n","\n","# 读取CSV文件和图片\n","df = pd.read_csv('/content/drive/MyDrive/archive/dogs.csv')\n","df_selected = df[df['labels'].isin([\"Airedale\", \"Beagle\", \"Bloodhound\", \"Bluetick\", \"Chihuahua\",\n","                                    \"Collie\", \"Dingo\", \"French Bulldog\", \"German Shepherd\",\n","                                    \"Malinois\", \"Newfoundland\", \"Pekinese\", \"Pomeranian\", \"Pug\", \"Vizsla\"])]\n","images = load_images(df_selected, '/content/drive/MyDrive/archive')\n","label_encoder = LabelEncoder()\n","labels = label_encoder.fit_transform(df_selected['labels'])\n","\n","# 划分训练集和测试集\n","X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n","\n","# 构建模型\n","def build_vgg16_model(input_shape, num_classes):\n","    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","    x = Flatten()(base_model.output)\n","    x = Dense(512, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    predictions = Dense(num_classes, activation='softmax')(x)\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    return model\n","\n","model = build_vgg16_model((224, 224, 3), len(np.unique(labels)))\n","\n","# 编译模型\n","model.compile(optimizer=Adam(learning_rate=0.0004),\n","              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n","\n","# 数据增强\n","datagen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=False)\n","\n","# 设置ModelCheckpoint\n","checkpoint_path = \"vgg16_best_model.h5\"\n","checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n","                             save_best_only=True,\n","                             monitor='val_accuracy',\n","                             mode='max',\n","                             verbose=1)\n","\n","# 训练模型，加入ModelCheckpoint回调\n","model.fit(datagen.flow(X_train, y_train, batch_size=32),\n","          epochs=30,\n","          validation_data=(X_test, y_test),\n","          callbacks=[checkpoint])\n","\n","# 评估模型\n","val_loss, val_acc = model.evaluate(X_test, y_test)\n","print(f\"Validation Accuracy: {val_acc}\")\n"],"metadata":{"id":"4rJpNniTdtx3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"00962421-ea5a-4d44-e309-7df4e018abff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]},{"output_type":"stream","name":"stdout","text":["48/48 [==============================] - ETA: 0s - loss: 2.4480 - sparse_categorical_accuracy: 0.2759 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r48/48 [==============================] - 1162s 24s/step - loss: 2.4480 - sparse_categorical_accuracy: 0.2759 - val_loss: 1.3674 - val_sparse_categorical_accuracy: 0.6154\n","Epoch 2/30\n","48/48 [==============================] - ETA: 0s - loss: 1.4394 - sparse_categorical_accuracy: 0.5285 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r48/48 [==============================] - 1196s 25s/step - loss: 1.4394 - sparse_categorical_accuracy: 0.5285 - val_loss: 0.9269 - val_sparse_categorical_accuracy: 0.7480\n","Epoch 3/30\n","48/48 [==============================] - ETA: 0s - loss: 1.0881 - sparse_categorical_accuracy: 0.6439 "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r48/48 [==============================] - 1185s 25s/step - loss: 1.0881 - sparse_categorical_accuracy: 0.6439 - val_loss: 0.7796 - val_sparse_categorical_accuracy: 0.7851\n","Epoch 4/30\n"," 2/48 [>.............................] - ETA: 15:03 - loss: 0.9754 - sparse_categorical_accuracy: 0.7500"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import os\n","\n","def load_and_preprocess_image(image_path, target_size=(224, 224)):\n","    img = image.load_img(image_path, target_size=target_size)\n","    img_array = image.img_to_array(img)\n","    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n","    return tf.keras.applications.mobilenet_v2.preprocess_input(img_array_expanded_dims)\n","\n","def predict_and_evaluate(model, image_dir):\n","    correct_predictions = 0\n","    total_images = 0\n","\n","    for root, dirs, files in os.walk(image_dir):\n","        for file in files:\n","            if file.lower().endswith(('png', 'jpg', 'jpeg')):\n","                img_path = os.path.join(root, file)\n","                processed_img = load_and_preprocess_image(img_path)\n","                prediction = model.predict(processed_img)\n","                predicted_class = np.argmax(prediction, axis=1)[0]\n","\n","                total_images += 1\n","\n","    accuracy = correct_predictions / total_images if total_images > 0 else 0\n","    print(f\"Accuracy: {accuracy:.2f}\")\n","\n","# 加载模型\n","model_path = 'vgg16_best_model.h5'\n","model = tf.keras.models.load_model(model_path)\n","\n","# 验证数据集的路径\n","validation_images_path = '/content/drive/MyDrive/archive/valid'\n","\n","# 进行预测并评估\n","predict_and_evaluate(model, validation_images_path)\n"],"metadata":{"id":"tM95kKy0lYfj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import load_model\n","import tensorflow as tf\n","\n","# 指定圖片文件夾路徑\n","test_images_directory = '/content/drive/MyDrive/archive/Testing set'\n","\n","# 加載模型\n","model = load_model('vgg16_best_model.h5', compile=False)\n","\n","# 讀取圖片並進行預測\n","def predict_images_from_directory(directory):\n","    predicted_labels = []\n","    file_names = []\n","    for file in os.listdir(directory):\n","        file_path = os.path.join(directory, file)\n","        img = image.load_img(file_path, target_size=(224, 224))\n","        img_array = image.img_to_array(img)\n","        img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n","        img_preprocessed = tf.keras.applications.mobilenet_v2.preprocess_input(img_array_expanded_dims)\n","\n","        prediction = model.predict(img_preprocessed)\n","        predicted_class = np.argmax(prediction, axis=1)\n","\n","        # 儲存文件名和預測結果\n","        file_names.append(file)\n","        predicted_labels.append(predicted_class[0])\n","\n","    return file_names, predicted_labels\n","\n","# 使用函數進行預測\n","file_names, predicted_classes = predict_images_from_directory(test_images_directory)\n","\n","# 創建結果DataFrame\n","results_df = pd.DataFrame({\n","    'FileName': file_names,\n","    'PredictedClass': predicted_classes\n","})\n","\n","# 將結果保存為Excel文件\n","results_df.to_excel('test_data.xlsx', index=False)\n"],"metadata":{"id":"l7D1Cqfrl1bW"},"execution_count":null,"outputs":[]}]}