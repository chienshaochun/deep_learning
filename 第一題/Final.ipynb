{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"K2Xw6tmko10J"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import os\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow import keras\n","from tensorflow.keras.layers import BatchNormalization, Conv2D, DepthwiseConv2D, Dropout, Flatten, Dense, AveragePooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from PIL import Image\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","\n","\n","# 定義模型保存路徑\n","model_save_path = './best_model/model_35_long_150_100/'\n","if not os.path.exists(model_save_path):\n","    os.makedirs(model_save_path)\n","\n","# 創建ModelCheckpoint回調，以在每個epoch後保存驗證損失最小的模型\n","mcp_save = ModelCheckpoint(filepath=model_save_path, save_best_only=True, monitor='val_sparse_categorical_accuracy', mode='max', verbose=1)\n","\n","weight_decay = 1e-4\n","\n","class Preact_resnet(keras.Model):\n","    def __init__(self, input_shape = (224,224,3) ):\n","        super(Preact_resnet, self).__init__()\n","        self.layer_1 = tf.keras.models.Sequential([\n","                        tf.keras.layers.Conv2D(32, 3, padding='same', strides=2,\n","                           activation=None, input_shape=input_shape, kernel_regularizer=regularizers.l2(weight_decay)),\n","                        BatchNormalization(),\n","                        tf.keras.layers.Activation('relu'),\n","                        tf.keras.layers.Dropout(0.1),\n","                        ])\n","        ## stage 1\n","        self.block_1 = tf.keras.models.Sequential([\n","\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(32, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","\n","\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(32, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.Dropout(0.1),\n","\n","            ])\n","        # shortcut_1 is identity\n","        self.block_2 = tf.keras.models.Sequential([\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(32, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","\n","\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(32, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.Dropout(0.1),\n","            ])\n","        # shortcut_2 is identity\n","\n","        ## stage 2\n","        self.block_3 = tf.keras.models.Sequential([\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=2, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(64, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(64, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(64, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.Dropout(0.1),\n","            ])\n","        self.shortcut_3 = tf.keras.layers.Conv2D(64, 1, activation=None, strides=2, kernel_regularizer=regularizers.l2(weight_decay))\n","\n","        self.block_4 = tf.keras.models.Sequential([\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(64, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(64, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(64, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.Dropout(0.1),\n","            ])\n","        # shortcut_4 is identity\n","\n","        ## stage 3\n","        self.block_5 = tf.keras.models.Sequential([\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=2, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(128, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(128, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(128, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.Dropout(0.1),\n","            ])\n","        self.shortcut_5 = tf.keras.layers.Conv2D(128, 1, activation=None, strides=2, kernel_regularizer=regularizers.l2(weight_decay))\n","\n","        self.block_6 = tf.keras.models.Sequential([\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(128, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(128, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.DepthwiseConv2D(3, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Conv2D(128, 1, padding='same', activation=None, strides=1, kernel_regularizer=regularizers.l2(weight_decay)),\n","            BatchNormalization(),\n","            tf.keras.layers.Activation('relu'),\n","            tf.keras.layers.Dropout(0.1),\n","            ])\n","        # shortcut_4 is identity\n","\n","        self.out_layer = tf.keras.models.Sequential([\n","\n","            ## output layer\n","            tf.keras.layers.AveragePooling2D((4, 4)),\n","            tf.keras.layers.Flatten(),\n","            tf.keras.layers.Dense(15, activation=None),\n","            ])\n","\n","\n","    def call(self, inputs):\n","        # inputs = (inputs - 0.4733) * 4 # mean = 0.4733, std = 0.251568723192402\n","\n","        x = self.layer_1(inputs)\n","\n","        # stage 1\n","        x = self.block_1(x) + x\n","        x = self.block_2(x) + x\n","\n","        # stage 2\n","        shortcut = self.shortcut_3(x)\n","        x = self.block_3(x) + shortcut\n","        x = self.block_4(x) + x\n","\n","        # stage 3\n","        shortcut = self.shortcut_5(x)\n","        x = self.block_5(x) + shortcut\n","        x = self.block_6(x) + x\n","\n","        x = self.out_layer(x)\n","\n","        return x\n","\n","# 讀取CSV文件\n","df = pd.read_csv('/content/drive/MyDrive/archive/dogs.csv')\n","\n","# 選擇指定類別\n","selected_breeds = [\n","    \"Airedale\", \"Beagle\", \"Bloodhound\", \"Bluetick\", \"Chihuahua\",\n","    \"Collie\", \"Dingo\", \"French Bulldog\", \"German Shepherd\",\n","    \"Malinois\", \"Newfoundland\", \"Pekinese\", \"Pomeranian\", \"Pug\", \"Vizsla\"\n","]\n","\n","# 過濾指定品種\n","df_selected = df[df['labels'].isin(selected_breeds)]\n","\n","# 加載圖片\n","def load_images(df):\n","    image_list = []\n","    for idx, row in df.iterrows():\n","        img = Image.open('/content/drive/MyDrive/archive/' + row['filepaths'])\n","        img = img.resize((224, 224))  # 使用224x224大小的圖像\n","        img_array = np.array(img) / 255.0\n","        image_list.append(img_array)\n","    return np.array(image_list)\n","\n","images = load_images(df_selected)\n","\n","# label邊碼\n","label_encoder = LabelEncoder()\n","labels = label_encoder.fit_transform(df_selected['labels'])\n","\n","# 分割訓練集\n","X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n","\n","\n","# 數據增強\n","datagen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=False\n",")\n","\n","# 實體化模型\n","model = Preact_resnet(input_shape=(224, 224, 3))\n","\n","# 定learning_rate\n","learning_rate = 0.0004\n","\n","# 定Epoch數量\n","epochs_num = 10\n","\n","# 編譯模型\n","model.compile(optimizer=Adam(learning_rate=learning_rate),  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[keras.metrics.SparseCategoricalAccuracy()])\n","\n","# 訓練模型，並將ModelCheckpoint加入到callbacks中\n","model.fit(datagen.flow(X_train, y_train, batch_size=32),\n","          epochs=epochs_num,\n","          validation_data=(X_test, y_test),\n","          callbacks=[mcp_save])  # 將mcp_save加入到訓練過程中\n","\n","# 加載最佳模型\n","best_model = tf.keras.models.load_model(model_save_path, compile=False)\n","\n","# 結果\n","val_loss, val_acc = model.evaluate(X_test, y_test)\n","print(f\"Test Accuracy with learning rate {learning_rate}: {val_acc}\\n\")\n","#0.001=0.52 0.0005=0.55 0.0001=0.32 0.0007=0.46 0.0004=0.57 0.0003=0.49 0.00035=0.46 0.00041=0.52 0.00042=00.579"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import os\n","\n","def load_and_preprocess_image(image_path, target_size=(224, 224)):\n","    img = image.load_img(image_path, target_size=target_size)\n","    img_array = image.img_to_array(img)\n","    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n","    return tf.keras.applications.mobilenet_v2.preprocess_input(img_array_expanded_dims)\n","\n","def predict_and_evaluate(model, image_dir):\n","    correct_predictions = 0\n","    total_images = 0\n","\n","    for root, dirs, files in os.walk(image_dir):\n","        for file in files:\n","            if file.lower().endswith(('png', 'jpg', 'jpeg')):\n","                img_path = os.path.join(root, file)\n","                processed_img = load_and_preprocess_image(img_path)\n","                prediction = model.predict(processed_img)\n","                predicted_class = np.argmax(prediction, axis=1)[0]\n","\n","                total_images += 1\n","\n","    accuracy = correct_predictions / total_images if total_images > 0 else 0\n","    print(f\"Accuracy: {accuracy:.2f}\")\n","\n","# 加载模型\n","model_path = './best_model/model_35_long_150_100/'\n","model = tf.keras.models.load_model(model_path)\n","\n","# 验证数据集的路径\n","validation_images_path = '/content/drive/MyDrive/archive/valid'\n","\n","# 进行预测并评估\n","predict_and_evaluate(model, validation_images_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":372},"id":"RVa1szdK7ygd","executionInfo":{"status":"error","timestamp":1711345291593,"user_tz":-480,"elapsed":7990,"user":{"displayName":"簡紹鈞","userId":"09701793831297041666"}},"outputId":"3b2946e6-c059-49db-8d97-c2446f437441"},"execution_count":2,"outputs":[{"output_type":"error","ename":"OSError","evalue":"No file or directory found at ./best_model/model_35_long_150_100/","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-f588e51c8b6a>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# 加载模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./best_model/model_35_long_150_100/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# 验证数据集的路径\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n","\u001b[0;31mOSError\u001b[0m: No file or directory found at ./best_model/model_35_long_150_100/"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import load_model\n","import tensorflow as tf\n","\n","# 指定圖片文件夾路徑\n","test_images_directory = '/content/drive/MyDrive/archive/Testing set'\n","\n","# 加載模型\n","model = load_model('./best_model/model_35_long_150_100/', compile=False)\n","\n","# 讀取圖片並進行預測\n","def predict_images_from_directory(directory):\n","    predicted_labels = []\n","    file_names = []\n","    for file in os.listdir(directory):\n","        file_path = os.path.join(directory, file)\n","        img = image.load_img(file_path, target_size=(224, 224))\n","        img_array = image.img_to_array(img)\n","        img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n","        img_preprocessed = tf.keras.applications.mobilenet_v2.preprocess_input(img_array_expanded_dims)\n","\n","        prediction = model.predict(img_preprocessed)\n","        predicted_class = np.argmax(prediction, axis=1)\n","\n","        # 儲存文件名和預測結果\n","        file_names.append(file)\n","        predicted_labels.append(predicted_class[0])\n","\n","    return file_names, predicted_labels\n","\n","# 使用函數進行預測\n","file_names, predicted_classes = predict_images_from_directory(test_images_directory)\n","\n","# 創建結果DataFrame\n","results_df = pd.DataFrame({\n","    'FileName': file_names,\n","    'PredictedClass': predicted_classes\n","})\n","\n","# 將結果保存為Excel文件\n","results_df.to_excel('test_data.xlsx', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":372},"id":"3X1r0e19Cqz9","executionInfo":{"status":"error","timestamp":1711345294888,"user_tz":-480,"elapsed":293,"user":{"displayName":"簡紹鈞","userId":"09701793831297041666"}},"outputId":"cc651c4b-0ac9-48c8-fe97-b6037708b43c"},"execution_count":3,"outputs":[{"output_type":"error","ename":"OSError","evalue":"No file or directory found at ./best_model/model_35_long_150_100/","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-76dadfef710b>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 加載模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./best_model/model_35_long_150_100/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 讀取圖片並進行預測\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n","\u001b[0;31mOSError\u001b[0m: No file or directory found at ./best_model/model_35_long_150_100/"]}]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"15DJPiASt6bHZlwcSPe0tv9_aLF88FxQY","authorship_tag":"ABX9TyMu7huGQnYbRtzsODGvTtvf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}