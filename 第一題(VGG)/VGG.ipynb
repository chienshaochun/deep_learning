{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"168hmFOWa4SWoJeZNQ_EPls9rifx7b2wn","authorship_tag":"ABX9TyOLz0TBng73Lr+GqgGSvoqv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import os\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from PIL import Image\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","\n","\n","# 定義模型保存路徑\n","model_save_path = './best_model/model_35_long_150_100/'\n","if not os.path.exists(model_save_path):\n","    os.makedirs(model_save_path)\n","\n","# 創建ModelCheckpoint回調，以在每個epoch後保存驗證損失最小的模型\n","mcp_save = ModelCheckpoint(filepath=model_save_path, save_best_only=True, monitor='val_sparse_categorical_accuracy', mode='max', verbose=1)\n","\n","# 讀取CSV文件\n","df = pd.read_csv('/content/drive/MyDrive/archive/dogs.csv')\n","\n","# 選擇指定類別\n","selected_breeds = [\n","    \"Airedale\", \"Beagle\", \"Bloodhound\", \"Bluetick\", \"Chihuahua\",\n","    \"Collie\", \"Dingo\", \"French Bulldog\", \"German Shepherd\",\n","    \"Malinois\", \"Newfoundland\", \"Pekinese\", \"Pomeranian\", \"Pug\", \"Vizsla\"\n","]\n","\n","# 過濾指定品種\n","df_selected = df[df['labels'].isin(selected_breeds)]\n","\n","# 加載圖片\n","def load_images(df):\n","    image_list = []\n","    for idx, row in df.iterrows():\n","        img = Image.open('/content/drive/MyDrive/archive/' + row['filepaths'])\n","        img = img.resize((224, 224))  # 使用224x224大小的圖像\n","        img_array = np.array(img) / 255.0\n","        image_list.append(img_array)\n","    return np.array(image_list)\n","\n","images = load_images(df_selected)\n","\n","# label邊碼\n","label_encoder = LabelEncoder()\n","labels = label_encoder.fit_transform(df_selected['labels'])\n","\n","# 分割訓練集\n","X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n","\n","# 數據增強\n","datagen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=False\n",")\n","\n","# 建構模型\n","def build_vgg16_model(input_shape, num_classes):\n","    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","    x = Flatten()(base_model.output)\n","    x = Dense(512, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    predictions = Dense(num_classes, activation='softmax')(x)\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    return model\n","\n","# 實體化模型\n","model = build_vgg16_model((224, 224, 3), len(np.unique(labels)))\n","\n","\n","\n","# 定learning_rate\n","learning_rate = 0.0001\n","\n","# 定Epoch數量\n","epochs_num = 20\n","\n","# 編譯模型\n","model.compile(optimizer=Adam(learning_rate=learning_rate),  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[keras.metrics.SparseCategoricalAccuracy()])\n","\n","# 訓練模型，並將ModelCheckpoint加入到callbacks中\n","model.fit(datagen.flow(X_train, y_train, batch_size=32),\n","          epochs=epochs_num,\n","          validation_data=(X_test, y_test),\n","          callbacks=[mcp_save])  # 將mcp_save加入到訓練過程中\n","\n","# 加載最佳模型\n","best_model = tf.keras.models.load_model(model_save_path, compile=False)\n","\n","# 結果\n","val_loss, val_acc = model.evaluate(X_test, y_test)\n","print(f\"Test Accuracy with learning rate {learning_rate}: {val_acc}\\n\")\n"],"metadata":{"id":"4rJpNniTdtx3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"049837ec-b836-4b60-dc68-9a4208588037"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n","Epoch 1/20\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]},{"output_type":"stream","name":"stdout","text":["48/48 [==============================] - ETA: 0s - loss: 2.2974 - sparse_categorical_accuracy: 0.2507 \n","Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.57294, saving model to ./best_model/model_35_long_150_100/\n","48/48 [==============================] - 1029s 21s/step - loss: 2.2974 - sparse_categorical_accuracy: 0.2507 - val_loss: 1.4928 - val_sparse_categorical_accuracy: 0.5729\n","Epoch 2/20\n","48/48 [==============================] - ETA: 0s - loss: 1.4799 - sparse_categorical_accuracy: 0.5073 \n","Epoch 2: val_sparse_categorical_accuracy improved from 0.57294 to 0.72414, saving model to ./best_model/model_35_long_150_100/\n","48/48 [==============================] - 1022s 21s/step - loss: 1.4799 - sparse_categorical_accuracy: 0.5073 - val_loss: 1.0023 - val_sparse_categorical_accuracy: 0.7241\n","Epoch 3/20\n","48/48 [==============================] - ETA: 0s - loss: 1.1458 - sparse_categorical_accuracy: 0.6406 \n","Epoch 3: val_sparse_categorical_accuracy improved from 0.72414 to 0.76658, saving model to ./best_model/model_35_long_150_100/\n","48/48 [==============================] - 1030s 22s/step - loss: 1.1458 - sparse_categorical_accuracy: 0.6406 - val_loss: 0.8728 - val_sparse_categorical_accuracy: 0.7666\n","Epoch 4/20\n","48/48 [==============================] - ETA: 0s - loss: 0.9641 - sparse_categorical_accuracy: 0.6883 \n","Epoch 4: val_sparse_categorical_accuracy improved from 0.76658 to 0.79045, saving model to ./best_model/model_35_long_150_100/\n","48/48 [==============================] - 1027s 21s/step - loss: 0.9641 - sparse_categorical_accuracy: 0.6883 - val_loss: 0.7722 - val_sparse_categorical_accuracy: 0.7905\n","Epoch 5/20\n","48/48 [==============================] - ETA: 0s - loss: 0.8230 - sparse_categorical_accuracy: 0.7427 \n","Epoch 5: val_sparse_categorical_accuracy improved from 0.79045 to 0.80371, saving model to ./best_model/model_35_long_150_100/\n","48/48 [==============================] - 1016s 21s/step - loss: 0.8230 - sparse_categorical_accuracy: 0.7427 - val_loss: 0.7067 - val_sparse_categorical_accuracy: 0.8037\n","Epoch 6/20\n","48/48 [==============================] - ETA: 0s - loss: 0.7445 - sparse_categorical_accuracy: 0.7659 \n","Epoch 6: val_sparse_categorical_accuracy improved from 0.80371 to 0.83024, saving model to ./best_model/model_35_long_150_100/\n","48/48 [==============================] - 1021s 21s/step - loss: 0.7445 - sparse_categorical_accuracy: 0.7659 - val_loss: 0.6386 - val_sparse_categorical_accuracy: 0.8302\n","Epoch 7/20\n","48/48 [==============================] - ETA: 0s - loss: 0.6587 - sparse_categorical_accuracy: 0.7911 \n","Epoch 7: val_sparse_categorical_accuracy did not improve from 0.83024\n","48/48 [==============================] - 1021s 21s/step - loss: 0.6587 - sparse_categorical_accuracy: 0.7911 - val_loss: 0.5869 - val_sparse_categorical_accuracy: 0.8249\n","Epoch 8/20\n","48/48 [==============================] - ETA: 0s - loss: 0.6082 - sparse_categorical_accuracy: 0.8117 \n","Epoch 8: val_sparse_categorical_accuracy did not improve from 0.83024\n","48/48 [==============================] - 1021s 21s/step - loss: 0.6082 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.6023 - val_sparse_categorical_accuracy: 0.8064\n","Epoch 9/20\n","48/48 [==============================] - ETA: 0s - loss: 0.5378 - sparse_categorical_accuracy: 0.8428 \n","Epoch 9: val_sparse_categorical_accuracy did not improve from 0.83024\n","48/48 [==============================] - 1019s 21s/step - loss: 0.5378 - sparse_categorical_accuracy: 0.8428 - val_loss: 0.5440 - val_sparse_categorical_accuracy: 0.8223\n","Epoch 10/20\n","48/48 [==============================] - ETA: 0s - loss: 0.4899 - sparse_categorical_accuracy: 0.8541 \n","Epoch 10: val_sparse_categorical_accuracy improved from 0.83024 to 0.84085, saving model to ./best_model/model_35_long_150_100/\n","48/48 [==============================] - 1024s 21s/step - loss: 0.4899 - sparse_categorical_accuracy: 0.8541 - val_loss: 0.5208 - val_sparse_categorical_accuracy: 0.8408\n","Epoch 11/20\n","48/48 [==============================] - ETA: 0s - loss: 0.4718 - sparse_categorical_accuracy: 0.8607 \n","Epoch 11: val_sparse_categorical_accuracy improved from 0.84085 to 0.85676, saving model to ./best_model/model_35_long_150_100/\n","48/48 [==============================] - 1030s 22s/step - loss: 0.4718 - sparse_categorical_accuracy: 0.8607 - val_loss: 0.5022 - val_sparse_categorical_accuracy: 0.8568\n","Epoch 12/20\n","48/48 [==============================] - ETA: 0s - loss: 0.4343 - sparse_categorical_accuracy: 0.8714 \n","Epoch 12: val_sparse_categorical_accuracy did not improve from 0.85676\n","48/48 [==============================] - 1016s 21s/step - loss: 0.4343 - sparse_categorical_accuracy: 0.8714 - val_loss: 0.5031 - val_sparse_categorical_accuracy: 0.8355\n","Epoch 13/20\n","48/48 [==============================] - ETA: 0s - loss: 0.3874 - sparse_categorical_accuracy: 0.8826 \n","Epoch 13: val_sparse_categorical_accuracy improved from 0.85676 to 0.85942, saving model to ./best_model/model_35_long_150_100/\n","48/48 [==============================] - 1018s 21s/step - loss: 0.3874 - sparse_categorical_accuracy: 0.8826 - val_loss: 0.5153 - val_sparse_categorical_accuracy: 0.8594\n","Epoch 14/20\n","48/48 [==============================] - ETA: 0s - loss: 0.3908 - sparse_categorical_accuracy: 0.8793 \n","Epoch 14: val_sparse_categorical_accuracy did not improve from 0.85942\n","48/48 [==============================] - 1017s 21s/step - loss: 0.3908 - sparse_categorical_accuracy: 0.8793 - val_loss: 0.5017 - val_sparse_categorical_accuracy: 0.8488\n","Epoch 15/20\n","48/48 [==============================] - ETA: 0s - loss: 0.3465 - sparse_categorical_accuracy: 0.9005 \n","Epoch 15: val_sparse_categorical_accuracy improved from 0.85942 to 0.86737, saving model to ./best_model/model_35_long_150_100/\n","48/48 [==============================] - 1015s 21s/step - loss: 0.3465 - sparse_categorical_accuracy: 0.9005 - val_loss: 0.4457 - val_sparse_categorical_accuracy: 0.8674\n","Epoch 16/20\n","48/48 [==============================] - ETA: 0s - loss: 0.3763 - sparse_categorical_accuracy: 0.8886 \n","Epoch 16: val_sparse_categorical_accuracy did not improve from 0.86737\n","48/48 [==============================] - 1011s 21s/step - loss: 0.3763 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.4749 - val_sparse_categorical_accuracy: 0.8594\n","Epoch 17/20\n","48/48 [==============================] - ETA: 0s - loss: 0.3080 - sparse_categorical_accuracy: 0.9131 \n","Epoch 17: val_sparse_categorical_accuracy did not improve from 0.86737\n","48/48 [==============================] - 1015s 21s/step - loss: 0.3080 - sparse_categorical_accuracy: 0.9131 - val_loss: 0.4781 - val_sparse_categorical_accuracy: 0.8594\n","Epoch 18/20\n","48/48 [==============================] - ETA: 0s - loss: 0.3013 - sparse_categorical_accuracy: 0.9118 \n","Epoch 18: val_sparse_categorical_accuracy did not improve from 0.86737\n","48/48 [==============================] - 1008s 21s/step - loss: 0.3013 - sparse_categorical_accuracy: 0.9118 - val_loss: 0.4658 - val_sparse_categorical_accuracy: 0.8435\n","Epoch 19/20\n","48/48 [==============================] - ETA: 0s - loss: 0.2635 - sparse_categorical_accuracy: 0.9231 "]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import os\n","\n","def load_and_preprocess_image(image_path, target_size=(224, 224)):\n","    img = image.load_img(image_path, target_size=target_size)\n","    img_array = image.img_to_array(img)\n","    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n","    return tf.keras.applications.mobilenet_v2.preprocess_input(img_array_expanded_dims)\n","\n","def predict_and_evaluate(model, image_dir):\n","    correct_predictions = 0\n","    total_images = 0\n","\n","    for root, dirs, files in os.walk(image_dir):\n","        for file in files:\n","            if file.lower().endswith(('png', 'jpg', 'jpeg')):\n","                img_path = os.path.join(root, file)\n","                processed_img = load_and_preprocess_image(img_path)\n","                prediction = model.predict(processed_img)\n","                predicted_class = np.argmax(prediction, axis=1)[0]\n","\n","                total_images += 1\n","\n","    accuracy = correct_predictions / total_images if total_images > 0 else 0\n","    print(f\"Accuracy: {accuracy:.2f}\")\n","\n","# 加载模型\n","model_path = './best_model/model_35_long_150_100/'\n","model = tf.keras.models.load_model(model_path)\n","\n","# 验证数据集的路径\n","validation_images_path = '/content/drive/MyDrive/archive/valid'\n","\n","# 进行预测并评估\n","predict_and_evaluate(model, validation_images_path)\n"],"metadata":{"id":"tM95kKy0lYfj","colab":{"base_uri":"https://localhost:8080/","height":372},"executionInfo":{"status":"error","timestamp":1711417116623,"user_tz":-480,"elapsed":8289,"user":{"displayName":"簡紹鈞","userId":"09701793831297041666"}},"outputId":"e2de73ce-f350-4c64-8404-c609ec93c0a6"},"execution_count":1,"outputs":[{"output_type":"error","ename":"OSError","evalue":"No file or directory found at ./best_model/model_35_long_150_100/","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f588e51c8b6a>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# 加载模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./best_model/model_35_long_150_100/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# 验证数据集的路径\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n","\u001b[0;31mOSError\u001b[0m: No file or directory found at ./best_model/model_35_long_150_100/"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import load_model\n","import tensorflow as tf\n","\n","# 指定圖片文件夾路徑\n","test_images_directory = '/content/drive/MyDrive/archive/Testing set'\n","\n","# 加載模型\n","model = load_model('./best_model/model_35_long_150_100/', compile=False)\n","\n","# 讀取圖片並進行預測\n","def predict_images_from_directory(directory):\n","    predicted_labels = []\n","    file_names = []\n","    for file in os.listdir(directory):\n","        file_path = os.path.join(directory, file)\n","        img = image.load_img(file_path, target_size=(224, 224))\n","        img_array = image.img_to_array(img)\n","        img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n","        img_preprocessed = tf.keras.applications.mobilenet_v2.preprocess_input(img_array_expanded_dims)\n","\n","        prediction = model.predict(img_preprocessed)\n","        predicted_class = np.argmax(prediction, axis=1)\n","\n","        # 儲存文件名和預測結果\n","        file_names.append(file)\n","        predicted_labels.append(predicted_class[0])\n","\n","    return file_names, predicted_labels\n","\n","# 使用函數進行預測\n","file_names, predicted_classes = predict_images_from_directory(test_images_directory)\n","\n","# 創建結果DataFrame\n","results_df = pd.DataFrame({\n","    'FileName': file_names,\n","    'PredictedClass': predicted_classes\n","})\n","\n","# 將結果保存為Excel文件\n","results_df.to_excel('test_data.xlsx', index=False)\n"],"metadata":{"id":"l7D1Cqfrl1bW","colab":{"base_uri":"https://localhost:8080/","height":372},"executionInfo":{"status":"error","timestamp":1711417136084,"user_tz":-480,"elapsed":331,"user":{"displayName":"簡紹鈞","userId":"09701793831297041666"}},"outputId":"93cfda67-4614-44a1-88b7-3831fa764481"},"execution_count":2,"outputs":[{"output_type":"error","ename":"OSError","evalue":"No file or directory found at ./best_model/model_35_long_150_100/","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-76dadfef710b>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 加載模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./best_model/model_35_long_150_100/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 讀取圖片並進行預測\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n","\u001b[0;31mOSError\u001b[0m: No file or directory found at ./best_model/model_35_long_150_100/"]}]}]}